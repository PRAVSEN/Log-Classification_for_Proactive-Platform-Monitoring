# ğŸ” Log Classification for Proactive Platform Monitoring

## ğŸ“˜ Project Overview

This capstone project focuses on building a machine learning pipeline to classify system log messages into categories such as `error` and `info`. The goal is to proactively alert platform engineers about potential issues before they escalate, enabling faster response and improved system reliability.

---

## ğŸ§  Problem Statement

Modern platforms generate thousands of log messages daily. Manually inspecting these logs is inefficient and error-prone. This project automates log classification to identify critical messages (`error`) and distinguish them from routine ones (`info`), helping engineers detect brewing issues early.

---

## ğŸ“Š Exploratory Data Analysis (EDA)

### ğŸ“ Dataset Overview
- **Rows**: 28,971
- **Columns**: 4
- **Fields**:
  - `Time`: timestamp of log entry
  - `service_name`: source of the log
  - `detected_level`: log severity (e.g., info, error)
  - `log`: unstructured log message text

### âœ… Missing Values
- No missing values detected across any columns.
- **Key Takeaway**: Dataset is complete and clean.

### ğŸ”¢ Data Types Distribution
- `object`: text-based columns
- `int64`: numeric identifiers and timestamps
- **Key Takeaway**: Majority of columns are text-based, followed by numeric types.

### ğŸ§® Service Names by Detected Level
- Grouped bar chart shows distribution of `info`, `error`, and `debug` logs across services.
- **Key Takeaway**: Error-level logs are concentrated in specific servicesâ€”potential system hotspots.

### ğŸ”¤ Frequent Words in Logs
- Tokenized `log` column and calculated word frequencies.
- Visualized using bar chart and word cloud.
- **Key Takeaway**: Common terms include `timeout`, `connection`, `error`, suggesting recurring system issues.

### â° Log Messages by Hour
- Converted timestamps from UTC to EST (UTCâˆ’5).
- Extracted hourly distribution of logs.
- **Key Takeaway**: Most logs are generated after business hoursâ€”likely due to ETL batch operations.

### ğŸ“ Log Message Length & Frequency
- Most log messages are under 500 bytes.
- **Key Takeaway**: ERROR logs tend to be longer due to stack traces, while INFO logs are typically concise.

---

## ğŸ§  Feature Engineering & Clustering

### ğŸ“ TF-IDF Embeddings
- Applied TF-IDF vectorization to extract semantic patterns.
- 2D projection shows consistent clustering between train and test sets.

### ğŸ” Clustering Techniques
- Applied DBSCAN and KMeans to reduced embeddings.
- **Key Takeaway**: Both methods generalize well across splits, capturing consistent structure.

---

## âš–ï¸ Scaling & KDE Visualization

### âœ… Scaling Best Practices
- Label encoding applied only to target variable
- Train-test split performed before scaling
- Avoided scaling one-hot encoded categorical features

### ğŸ“ˆ Importance of Scaling
- **StandardScaler** centers SVD components to mean 0 and scales to unit variance.
- Applied only to continuous features (SVD components).
- Prevents data leakage and preserves categorical meaning.

### ğŸ“Š KDE Output Summary
- **Before Scaling**: SVD components show natural separation but varied ranges.
- **After Scaling**: Distributions are centered and standardized.
- **Key Takeaway**: KDE confirms scaling preserves class separation while normalizing feature behavior.

---

## ğŸ”§ Pipeline Summary

### 1. Data Preparation
- Loaded logs from `Log-Classification_Capstone_Final.csv`
- Filtered for `error` and `info`
- Encoded target labels using `LabelEncoder`

### 2. Feature Engineering
- **Text**: TF-IDF vectorization
- **Time**: Extracted hour from timestamp
- **Service**: One-hot encoded `service_name`
- **Dimensionality Reduction**: Truncated SVD (3 components)
- **Scaling**: StandardScaler applied to SVD components only

### 3. Modeling
- Train/test split (80/20) with stratified sampling
- Combined scaled SVD + unscaled metadata
- Trained classifiers with `GridSearchCV`:
  - Logistic Regression
  - K-Nearest Neighbors
  - Decision Tree
  - Random Forest
  - Support Vector Machine (Linear Kernel)
- Included Dummy Classifier as baseline

### 4. Evaluation
- âœ… Cross-validated predictions (`cross_val_predict`)
- âœ… Confusion matrix visualization
- âœ… ROC-AUC curves for model discrimination
- âœ… Precision, recall, F1-score, and support metrics

---

## ğŸ Final Thoughts

This project demonstrates a scalable approach to log classification, enabling proactive platform monitoring. Future enhancements may include:

- Real-time log ingestion and classification
- Integration with alerting systems
- Deployment as a microservice for production use
